{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 files to process...\n",
      "\n",
      "[1/43] Loaded data/holistic_landmarks_Adjectives_1of8.npz ‚Äî data shape: (5991,), label shape: (5991,)\n",
      "[2/43] Loaded data/holistic_landmarks_Adjectives_2of8.npz ‚Äî data shape: (6596,), label shape: (6596,)\n",
      "[3/43] Loaded data/holistic_landmarks_Adjectives_3of8.npz ‚Äî data shape: (6636,), label shape: (6636,)\n",
      "[4/43] Loaded data/holistic_landmarks_Adjectives_4of8.npz ‚Äî data shape: (5617,), label shape: (5617,)\n",
      "[5/43] Loaded data/holistic_landmarks_Adjectives_5of8.npz ‚Äî data shape: (6042,), label shape: (6042,)\n",
      "[6/43] Loaded data/holistic_landmarks_Adjectives_6of8.npz ‚Äî data shape: (5848,), label shape: (5848,)\n",
      "[7/43] Loaded data/holistic_landmarks_Adjectives_7of8.npz ‚Äî data shape: (5833,), label shape: (5833,)\n",
      "[8/43] Loaded data/holistic_landmarks_Adjectives_8of8.npz ‚Äî data shape: (3861,), label shape: (3861,)\n",
      "[9/43] Loaded data/holistic_landmarks_Animals_1of2.npz ‚Äî data shape: (7269,), label shape: (7269,)\n",
      "[10/43] Loaded data/holistic_landmarks_Animals_2of2.npz ‚Äî data shape: (4504,), label shape: (4504,)\n",
      "[11/43] Loaded data/holistic_landmarks_Clothes_1of2.npz ‚Äî data shape: (6173,), label shape: (6173,)\n",
      "[12/43] Loaded data/holistic_landmarks_Clothes_2of2.npz ‚Äî data shape: (6218,), label shape: (6218,)\n",
      "[13/43] Loaded data/holistic_landmarks_Colours_1of2.npz ‚Äî data shape: (5674,), label shape: (5674,)\n",
      "[14/43] Loaded data/holistic_landmarks_Colours_2of2.npz ‚Äî data shape: (6497,), label shape: (6497,)\n",
      "[15/43] Loaded data/holistic_landmarks_Days_and_Time_1of3.npz ‚Äî data shape: (4705,), label shape: (4705,)\n",
      "[16/43] Loaded data/holistic_landmarks_Days_and_Time_2of3.npz ‚Äî data shape: (3774,), label shape: (3774,)\n",
      "[17/43] Loaded data/holistic_landmarks_Days_and_Time_3of3.npz ‚Äî data shape: (2687,), label shape: (2687,)\n",
      "[18/43] Loaded data/holistic_landmarks_Electronics_1of2.npz ‚Äî data shape: (3443,), label shape: (3443,)\n",
      "[19/43] Loaded data/holistic_landmarks_Electronics_2of2.npz ‚Äî data shape: (3141,), label shape: (3141,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def merge_npz_to_single_npy(data_dir='data', data_out='Combined_holistic_landmarks_data.npy', labels_out='Combined_holistic_landmarks_labels.npy'):\n",
    "    npz_files = sorted(glob.glob(os.path.join(data_dir, \"holistic_landmarks_*.npz\")))\n",
    "\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(f\"Found {len(npz_files)} files to process...\\n\")\n",
    "\n",
    "    for i, file in enumerate(npz_files):\n",
    "        try:\n",
    "            npz = np.load(file, allow_pickle=True)\n",
    "            data_batch = np.array(npz['X'], dtype=object)\n",
    "            labels_batch = np.array(npz['y'])\n",
    "\n",
    "            print(f\"[{i+1}/{len(npz_files)}] Loaded {file} ‚Äî data shape: {data_batch.shape}, label shape: {labels_batch.shape}\")\n",
    "\n",
    "            all_data.append(data_batch)\n",
    "            all_labels.append(labels_batch)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading file {file}: {type(e).__name__}: {e}\")\n",
    "            break\n",
    "\n",
    "    print(\"\\nüì¶ Loaded all files (except failed ones).\")\n",
    "    for i, d in enumerate(all_data):\n",
    "        print(f\" - Batch {i}: shape={d.shape}, dtype={d.dtype}\")\n",
    "\n",
    "    if not all_data or not all_labels:\n",
    "        print(\"No valid data found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Combine all batches\n",
    "    try:\n",
    "        full_data = np.concatenate(all_data, axis=0)\n",
    "        full_labels = np.concatenate(all_labels, axis=0)\n",
    "        print(\"üîó Data concatenated successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Concatenation failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # Save once, in proper .npy format\n",
    "    np.save(data_out, full_data)\n",
    "    np.save(labels_out, full_labels)\n",
    "\n",
    "    print(\"\\n‚úÖ Done saving combined files!\")\n",
    "    print(f\"üìê Final Landmarks shape: {full_data.shape}\")\n",
    "    print(f\"üè∑Ô∏è Final Labels shape: {full_labels.shape}\")\n",
    "\n",
    "# Run it\n",
    "merge_npz_to_single_npy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded successfully.\n",
      "Keys in file: ['X', 'y']\n",
      "X shape: (3332,)\n",
      "y shape: (3332,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace with the exact filename if needed\n",
    "filename = \"data/holistic_landmarks_Home_2of4.npz\"\n",
    "\n",
    "try:\n",
    "    npz = np.load(filename, allow_pickle=True)\n",
    "    print(\"Loaded successfully.\")\n",
    "    print(\"Keys in file:\", npz.files)\n",
    "    \n",
    "    X = npz['X']\n",
    "    y = npz['y']\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load {filename}\")\n",
    "    print(f\"   {type(e).__name__}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_appended_npy(file_path):\n",
    "    arrays = []\n",
    "    with open(file_path, 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                arrays.append(np.load(f, allow_pickle=True))\n",
    "            except (ValueError, EOFError):  # Catch both ValueError & EOFError\n",
    "                break\n",
    "    return np.concatenate(arrays, axis=0)\n",
    "\n",
    "x = load_appended_npy('Combined_holistic_landmarks_data.npy')\n",
    "y = load_appended_npy('Combined_holistic_landmarks_labels.npy')\n",
    "\n",
    "np.save(\"final_landmarks.npy\", x)\n",
    "np.save(\"final_labels.npy\", y)\n",
    "\n",
    "print(f\"Landmarks shape: {x.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_84851/1236551609.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Count the occurrences of each label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlabel_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Get the unique labels and their counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m         '''\n\u001b[1;32m    576\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = Counter(y)\n",
    "\n",
    "# Get the unique labels and their counts\n",
    "labels, counts = zip(*label_counts.items())\n",
    "\n",
    "# Plotting the label distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, counts, color='skyblue')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels in the Dataset')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Alternatively, you can print the counts\n",
    "print(\"Label Distribution:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f'Label: {label}, Count: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing items in landmarks\n",
    "missing_landmarks = []\n",
    "for i, landmark in enumerate(x):\n",
    "    if isinstance(landmark, np.ndarray):\n",
    "        if np.any(np.isnan(landmark)):\n",
    "            missing_landmarks.append(i)\n",
    "\n",
    "# Check for missing labels (None or empty strings)\n",
    "missing_labels = [i for i, label in enumerate(y) if label is None or label == '']\n",
    "\n",
    "# Count missing items\n",
    "num_missing_landmarks = len(missing_landmarks)\n",
    "num_missing_labels = len(missing_labels)\n",
    "\n",
    "# Print the results\n",
    "print(f'Total missing landmarks: {num_missing_landmarks}')\n",
    "print(f'Total missing labels: {num_missing_labels}')\n",
    "\n",
    "# Optionally, find the indices of the missing items\n",
    "print(f'Indices of missing landmarks: {missing_landmarks}')\n",
    "print(f'Indices of missing labels: {missing_labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of each landmark in x to find inconsistencies\n",
    "landmark_shapes = [np.array(landmark).shape for landmark in x if isinstance(landmark, list)]\n",
    "\n",
    "# Identify the unique shapes\n",
    "unique_shapes = set(landmark_shapes)\n",
    "print(f\"Unique shapes found: {unique_shapes}\")\n",
    "\n",
    "# Fixing inconsistent landmarks by padding or truncating\n",
    "fixed_landmarks = []\n",
    "for landmark in x:\n",
    "    if isinstance(landmark, list):\n",
    "        landmark_array = np.array(landmark)\n",
    "        if landmark_array.shape[0] < 543:\n",
    "            # Pad with zeros if less than 543\n",
    "            padded = np.pad(landmark_array, ((0, 543 - landmark_array.shape[0]), (0, 0)), mode='constant')\n",
    "            fixed_landmarks.append(padded)\n",
    "        elif landmark_array.shape[0] > 543:\n",
    "            # Truncate if greater than 543\n",
    "            truncated = landmark_array[:543]\n",
    "            fixed_landmarks.append(truncated)\n",
    "        else:\n",
    "            # Append as is if it has the correct shape\n",
    "            fixed_landmarks.append(landmark_array)\n",
    "\n",
    "# Convert the list of fixed landmarks to a numpy array\n",
    "x_fixed = np.array(fixed_landmarks)\n",
    "print(f\"Fixed landmarks shape: {x_fixed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "landmarks_data_scaled = scaler.fit_transform(x_fixed.reshape(-1, x_fixed.shape[-1]))  # Flatten for scaling\n",
    "landmarks_data_scaled = landmarks_data_scaled.reshape(x_fixed.shape)  # Reshape back to original\n",
    "print(f'Scaled landmarks shape: {landmarks_data_scaled.shape}')\n",
    "\n",
    "# Save the scaler to a file\n",
    "joblib.dump(scaler, '30Labels_scaler_filename.pkl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for the sequences with the highest and lowest values\n",
    "for i in range(5):\n",
    "    plt.plot(landmarks_data_scaled[i].flatten())\n",
    "    plt.title(f\"Sample {i} - Sequence\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(landmarks_data_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the split data\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifically Creating Data using SMOTE and then Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Oversample the minority classes using SMOTE (optional)\n",
    "smote = SMOTE()\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train.reshape((x_train.shape[0], -1)), y_train)\n",
    "x_train_resampled = x_train_resampled.reshape((x_train_resampled.shape[0], x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "# Print the shapes of the split data\n",
    "print(f\"x_train shape: {x_train_resampled.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_train shape: {y_train_resampled.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = Counter(y_train_resampled)\n",
    "\n",
    "# Get the unique labels and their counts\n",
    "labels, counts = zip(*label_counts.items())\n",
    "\n",
    "# Plotting the label distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, counts, color='skyblue')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels in the Dataset')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Alternatively, you can print the counts\n",
    "print(\"Label Distribution of Y Training:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f'Label: {label}, Count: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder on y_train (since y_train contains all possible labels)\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_resampled)\n",
    "y_test_encoded = label_encoder.transform(y_test)  # Apply the same transformation to y_test\n",
    "\n",
    "# Check the encoded labels\n",
    "print(f\"Encoded y_train: {y_train_encoded[:5]}\")  # Print first 5 encoded labels for reference\n",
    "print(f\"Encoded y_test: {y_test_encoded[:5]}\")\n",
    "\n",
    "# Also, let's map the classes for reference\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(f\"Label Mapping: {label_mapping}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Check the distribution of the encoded labels\n",
    "print(f\"y_train_encoded distribution: {Counter(y_train_encoded)}\")\n",
    "print(f\"y_test_encoded distribution: {Counter(y_test_encoded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_train shape: {x_train_resampled.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_train shape: {y_train_encoded.shape}\")\n",
    "print(f\"y_test shape: {y_test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import (Input, Bidirectional, LSTM, BatchNormalization, Dropout, \n",
    "                          Attention, Flatten, Dense, LeakyReLU, Conv1D, MaxPooling1D)\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "input_shape = (x_train_resampled.shape[1], x_train_resampled.shape[2])\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# First Bidirectional LSTM layer\n",
    "lstm_out1 = Bidirectional(LSTM(256, return_sequences=True))(input_layer)\n",
    "lstm_out1 = BatchNormalization()(lstm_out1)\n",
    "lstm_out1 = Dropout(0.2)(lstm_out1)  # Reduce dropout\n",
    "\n",
    "# Second Bidirectional LSTM layer\n",
    "lstm_out2 = Bidirectional(LSTM(256, return_sequences=True))(lstm_out1)\n",
    "lstm_out2 = BatchNormalization()(lstm_out2)\n",
    "# Optionally, remove dropout here if needed\n",
    "\n",
    "# Attention layer\n",
    "attention_out = Attention()([lstm_out2, lstm_out2])\n",
    "\n",
    "# Flatten the output of attention\n",
    "flattened = Flatten()(attention_out)\n",
    "\n",
    "# Dense layers with reduced L2 regularization\n",
    "dense1 = Dense(128, kernel_regularizer=l2(0.001))(flattened)\n",
    "dense1 = LeakyReLU()(dense1)\n",
    "dense1 = BatchNormalization()(dense1)\n",
    "dense1 = Dropout(0.3)(dense1)\n",
    "\n",
    "dense2 = Dense(64, kernel_regularizer=l2(0.001))(dense1)\n",
    "dense2 = LeakyReLU()(dense2)\n",
    "dense2 = BatchNormalization()(dense2)\n",
    "dense2 = Dropout(0.3)(dense2)\n",
    "\n",
    "# Output layer for classification\n",
    "output_layer = Dense(num_classes, activation='softmax')(dense2)\n",
    "\n",
    "# Create and compile the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x_train_resampled,\n",
    "    y_train_encoded,\n",
    "    validation_data=(x_test, y_test_encoded),\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    callbacks = [early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "if early_stopping.stopped_epoch > 0:\n",
    "    print(f\"Training stopped early at epoch: {early_stopping.stopped_epoch + 1}\")\n",
    "    print(f\"Weights restored from epoch: {early_stopping.best_epoch + 1}\")\n",
    "else:\n",
    "    print(\"Training completed without early stopping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training and validation accuracy from the history\n",
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Extract training and validation loss from the history (optional)\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "# Print the final training and validation accuracy in the desired format\n",
    "print(f\"Final Training Accuracy: {training_accuracy[-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {validation_accuracy[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training and validation accuracy from the history\n",
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Extract training and validation loss from the history (optional)\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "# Print the final training and validation accuracy in the desired format\n",
    "print(f\"Final Training Accuracy: {training_accuracy[-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {validation_accuracy[-1]:.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Get predictions from the trained model (using the model, not history)\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_classes)\n",
    "\n",
    "# Create a figure with a high resolution (e.g., 1080x1920 pixels)\n",
    "plt.figure(figsize=(19.2, 10.8))  # 1920/100 and 1080/100 for a 100 DPI image\n",
    "\n",
    "# Display confusion matrix with a larger axis\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_train_encoded))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=plt.gca())  # Plot on the current axis with the desired size\n",
    "\n",
    "# Customize the plot title\n",
    "plt.title(\"30 Labels Test Confusion Matrix\")\n",
    "\n",
    "# Save the figure in high resolution (1080x1920)\n",
    "plt.savefig(\"confusion_matrix_1080x1920.png\", dpi=100, bbox_inches='tight')  # You can increase DPI for higher quality\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict(x_train_resampled)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_train_encoded, y_pred_classes)\n",
    "\n",
    "# Create a figure with a high resolution (e.g., 1080x1920 pixels)\n",
    "plt.figure(figsize=(19.2, 10.8))  # 1920/100 and 1080/100 for a 100 DPI image\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_train_encoded))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=plt.gca())  # Plot on the current larger axis\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"30 Labels + LSTM Training Confusion Matrix\")\n",
    "\n",
    "# Save the figure in high resolution (1080x1920)\n",
    "plt.savefig(\"Train confusion_matrix_1080x1920.png\", dpi=100, bbox_inches='tight')  # You can increase DPI for higher quality\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming validation_accuracy is a single numeric value\n",
    "model_name = '30 `labels' + f\"{validation_accuracy[-1]:.4f}\"\n",
    "model.save(f\"Model_{model_name}.h5\")  # Save with .h5 extension\n",
    "print(f\"Model {model_name} was saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1744140890.641495    4032 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1744140890.645047    4032 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('Model_30_Labels 0.9501.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32345/3548087762.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Model Loss: {loss:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Model Accuracy: {accuracy:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "loss, accuracy = loaded_model.evaluate(x_test, y_test_encoded, verbose=0)\n",
    "\n",
    "print(f'Model Loss: {loss:.4f}')\n",
    "print(f'Model Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdud0e29h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdud0e29h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpdud0e29h'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 543, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 25), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138870207184416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870207182304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870207172624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870207177728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870207178784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870207180896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188759296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188760000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188754720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188757008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188610432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188613248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188615360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188472656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188461920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188466848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188761584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188763344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188758592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188762112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188765808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188763872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188767040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188768272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188764224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188765104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188768624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188760880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188820960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188819904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188818496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188819024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188824304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138870188819552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1744140904.732972    4032 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1744140904.733024    4032 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-04-09 01:05:04.734312: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpdud0e29h\n",
      "2025-04-09 01:05:04.740404: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-04-09 01:05:04.740436: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpdud0e29h\n",
      "I0000 00:00:1744140904.786863    4032 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "2025-04-09 01:05:04.789695: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-04-09 01:05:05.210574: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpdud0e29h\n",
      "2025-04-09 01:05:05.248342: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 514036 microseconds.\n",
      "2025-04-09 01:05:05.929136: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-04-09 01:05:10.060283: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3993] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x256xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x256xf32>>>, tensor<i32>, tensor<?x256xf32>) -> (tensor<!tf_type.variant<tensor<?x256xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x256xf32>>>, tensor<2xi32>) -> (tensor<543x?x256xf32>) : {device = \"\", num_elements = 543 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#model = tf.keras.models.load_model(f\"{model_name}.h5\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
    "\n",
    "# Fix for TensorListReserve / dynamic RNN ops\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4032/1507150972.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scaler.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label_encoder.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
