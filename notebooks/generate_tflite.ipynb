{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b370b5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 12:10:36.325181: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-02 12:10:36.330354: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-02 12:10:36.344004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746168036.370337   31377 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746168036.377993   31377 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746168036.391864   31377 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746168036.391885   31377 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746168036.391888   31377 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746168036.391891   31377 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-02 12:10:36.396140: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1746168039.160347   31377 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1746168039.165030   31377 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_name = '226_labels0.9608'\n",
    "loaded_model = load_model(f\"../models/Model_{model_name}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62413e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import (Input, Bidirectional, LSTM, BatchNormalization, Dropout, \n",
    "                          MultiHeadAttention, Flatten, Dense, LeakyReLU, Conv1D, MaxPooling1D, GlobalAveragePooling1D)\n",
    "from keras.regularizers import l2\n",
    "\n",
    "input_shape = loaded_model.input_shape[1:]  # Get shape from loaded model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "#Convolution Layer\n",
    "conv = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "conv = MaxPooling1D(pool_size=2)(conv)\n",
    "# CPU-friendly LSTM (unroll=True, explicit activations)\n",
    "lstm_out1 = Bidirectional(LSTM(256, return_sequences=True, activation='tanh',\n",
    "                               recurrent_activation='sigmoid', unroll=True))(conv)\n",
    "lstm_out1 = BatchNormalization()(lstm_out1)\n",
    "lstm_out1 = Dropout(0.2)(lstm_out1)\n",
    "\n",
    "lstm_out2 = Bidirectional(LSTM(256, return_sequences=True, activation='tanh',\n",
    "                               recurrent_activation='sigmoid', unroll=True))(lstm_out1)\n",
    "lstm_out2 = BatchNormalization()(lstm_out2)\n",
    "\n",
    "lstm_out3 = Bidirectional(LSTM(256, return_sequences=True, activation='tanh',\n",
    "                               recurrent_activation='sigmoid', unroll=True))(lstm_out2)\n",
    "lstm_out3 = BatchNormalization()(lstm_out3)\n",
    "\n",
    "attention_out = MultiHeadAttention(num_heads=4, key_dim=64)(lstm_out3, lstm_out3)\n",
    "\n",
    "pooled=GlobalAveragePooling1D()(attention_out)\n",
    "\n",
    "dense1 = Dense(128, kernel_regularizer=l2(1e-4))(pooled)\n",
    "dense1 = LeakyReLU()(dense1)\n",
    "dense1 = BatchNormalization()(dense1)\n",
    "dense1 = Dropout(0.2)(dense1)\n",
    "\n",
    "dense2 = Dense(64, kernel_regularizer=l2(1e-4))(dense1)\n",
    "dense2 = LeakyReLU()(dense2)\n",
    "dense2 = BatchNormalization()(dense2)\n",
    "dense2 = Dropout(0.2)(dense2)\n",
    "\n",
    "output_layer = Dense(loaded_model.output_shape[1], activation='softmax')(dense2)\n",
    "\n",
    "model_cpu = Model(inputs=input_layer, outputs=output_layer)\n",
    "model_cpu.set_weights(loaded_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9493debe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqmvm_0_p/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqmvm_0_p/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpqmvm_0_p'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 543, 3), dtype=tf.float32, name='keras_tensor_41')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 226), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138633220641312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633181174192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138634301923296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633181175600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633180862192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633180872224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633466684768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138634358905264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633177787632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633180868880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633177777600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633180969648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633180965248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633181137552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633181140368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633181138080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633181148816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633181142128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633181147936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633181140192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633181141248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633181141952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633156802896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633156803776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633156804304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633156802368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157132352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633156800608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157135168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157137104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157135520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157137984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157145024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157141856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157144320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157145552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157148016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157146256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157140624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157200880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157208448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157205280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157209856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157207744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157208976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157210384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157208624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157316976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157318384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157316272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157317504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157318912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157327184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138633157324016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1746168071.465826   31377 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1746168071.465882   31377 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-05-02 12:11:11.467137: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpqmvm_0_p\n",
      "2025-05-02 12:11:11.528317: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-05-02 12:11:11.528352: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpqmvm_0_p\n",
      "I0000 00:00:1746168072.179095   31377 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "2025-05-02 12:11:12.198160: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-05-02 12:11:13.531646: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpqmvm_0_p\n",
      "2025-05-02 12:11:14.630334: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 3163205 microseconds.\n",
      "2025-05-02 12:11:17.196904: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_cpu)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(f\"../models/{model_name}.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
