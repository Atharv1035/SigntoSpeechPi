{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "target_dirs = []\n",
    "base_dir = 'dataset/include'\n",
    "for entry in os.listdir(base_dir):\n",
    "    first_path = os.path.join(base_dir, entry)\n",
    "    if os.path.isdir(first_path):\n",
    "        for sub_entry in os.listdir(first_path):\n",
    "            second_path = os.path.join(first_path, sub_entry)\n",
    "            if os.path.isdir(second_path):\n",
    "                target_dirs.append(second_path)\n",
    "                print(second_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_holistic_landmarks(frame, holistic):\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = holistic.process(rgb_frame)\n",
    "\n",
    "    hand_landmarks = []\n",
    "    face_landmarks = []\n",
    "    pose_landmarks = []\n",
    "\n",
    "    if results.left_hand_landmarks:\n",
    "        hand_landmarks.extend([(lm.x, lm.y, lm.z) for lm in results.left_hand_landmarks.landmark])\n",
    "    if results.right_hand_landmarks:\n",
    "        hand_landmarks.extend([(lm.x, lm.y, lm.z) for lm in results.right_hand_landmarks.landmark])\n",
    "\n",
    "    if results.face_landmarks:\n",
    "        face_landmarks.extend([(lm.x, lm.y, lm.z) for lm in results.face_landmarks.landmark])\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        pose_landmarks.extend([(lm.x, lm.y, lm.z) for lm in results.pose_landmarks.landmark])\n",
    "\n",
    "    all_landmarks = {\n",
    "        'hand_landmarks': np.array(hand_landmarks) if hand_landmarks else None,\n",
    "        'face_landmarks': np.array(face_landmarks) if face_landmarks else None,\n",
    "        'pose_landmarks': np.array(pose_landmarks) if pose_landmarks else None,\n",
    "    }\n",
    "    \n",
    "    return all_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_videos(root_folder):\n",
    "    holistic = mp_holistic.Holistic(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "    dataset = []\n",
    "    labels = []\n",
    "\n",
    "    sign_folders = os.listdir(root_folder)\n",
    "    print(sign_folders)\n",
    "    for sign_folder in sign_folders:\n",
    "        sign_path = os.path.join(root_folder, sign_folder)\n",
    "        print(f'Processing subcategory: {sign_folder}')\n",
    "\n",
    "        if os.path.isdir(sign_path):\n",
    "            video_files = [filename for filename in os.listdir(sign_path) \n",
    "                           if filename.endswith(('.MOV', '.mp4', '.avi', '.mkv', '.wmv', '.flv', '.webm'))]\n",
    "            \n",
    "            current_video_count = len(video_files)\n",
    "            print(f'Number of videos files in {sign_folder}: {current_video_count}')\n",
    "            \n",
    "            for video_file in video_files:\n",
    "                video_path = os.path.join(sign_path, video_file)\n",
    "                print(f'Processing video: {video_path}')\n",
    "\n",
    "                # Open video file\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "                while cap.isOpened():\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "\n",
    "                    # Extract landmarks from the original frame\n",
    "                    landmarks = extract_holistic_landmarks(frame, holistic)\n",
    "                    if (landmarks['hand_landmarks'] is not None or \n",
    "                        landmarks['face_landmarks'] is not None or \n",
    "                        landmarks['pose_landmarks'] is not None):\n",
    "                        combined_landmarks = []\n",
    "                        if landmarks['hand_landmarks'] is not None:\n",
    "                            combined_landmarks.extend(landmarks['hand_landmarks'])\n",
    "                        if landmarks['face_landmarks'] is not None:\n",
    "                            combined_landmarks.extend(landmarks['face_landmarks'])\n",
    "                        if landmarks['pose_landmarks'] is not None:\n",
    "                            combined_landmarks.extend(landmarks['pose_landmarks'])\n",
    "\n",
    "                        dataset.append(combined_landmarks)\n",
    "                        labels.append(sign_folder)  \n",
    "\n",
    "                cap.release()\n",
    "\n",
    "    # Convert dataset and labels to numpy arrays\n",
    "    dataset = np.array(dataset, dtype=object)  \n",
    "    labels = np.array(labels)\n",
    "\n",
    "    name = os.path.basename(os.path.dirname(root_folder)) \n",
    "\n",
    "    save_dir = \"data\"\n",
    "    np.savez_compressed(f\"{save_dir}/holistic_landmarks_{name}.npz\", X=dataset, y=labels)\n",
    "\n",
    "    # Clean up\n",
    "    holistic.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in target_dirs[]:\n",
    "    name = os.path.basename(os.path.dirname(path))\n",
    "    process_videos(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
